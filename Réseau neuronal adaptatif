
--# Main
function setup()
    -- and
    -- entree
    x = {{0, 0},
        {0, 1},
        {1, 0},
        {1, 1}}
    -- 
    y = {{0}, 
        {1}, 
        {1}, 
        {0}}
    -- reseau neuronal capable de prendre en parametre n nombre de neurones sur n nombre de couches cacheés
    
    --[[ reseau a :
    entree : 2 entrees
    cache : 2 neurones, 2 poids par neurone
    sortie: 1 neurone, 2 poids par neurone
    ]]
    
    -- INITIALISATION
    teta = 0.1
    -- poids et biais des couche cache
    Wc, Bc = poids_biais(x[1], 2) 
    Wc2, Bc2 = poids_biais(Wc, 2)
    -- poids et biais de la couche de sortie
    Ws, Bs = poids_biais(Wc2, #y[1])
    
end

cycle = 1
taux_reussite_moyen = 0
hh = 1
texte = false
posx = WIDTH/2
epoch = 0
-- (maj_sortie) entre, poids, biais, sortie1, sortie2
-- (maj_entree) entre, poids1, poids2, biais, sortie, delta__

function draw()
    background(68)
    --if taux_reussite_moyen < 97 then
    if epoch < 3000 then
        X = x[cycle]
        -- sorties de la premiere couche cachee
        C = sortie(X, Wc, Bc, posx - 80, "relu")
        C2 = sortie(C, Wc2, Bc2, posx, "relu")
        -- sorties de la couche de sortie
        S = sortie(C2, Ws, Bs, posx + 80, "sigmoide")
        
        -- mise a jour des poids de la couche de sortie
        Ws, Bs, Ds = maj_poids_biais_sortie(C2, Ws, Bs, S, y, "sigmoide")
        -- mise a jour des poids des couches cachee
        Wc2, Bc2, Dc2 = maj_poids_biais_cache(C, Ws, Wc2, Bc2, C2, Ds, "relu")
        Wc, Bc, Dc = maj_poids_biais_cache(X, Wc2, Wc, Bc, C, Dc2, "relu")
        -- erreurs
        
        erreur = subMatrix(y[cycle], S)
        taux_reussite = subScalarinv(100, multiplyScalarabs(erreur, 100))
        printMatrixln(taux_reussite)
        taux_reussite_moyen = sumMatrix(taux_reussite)/#taux_reussite
        epoch = epoch + 1
        if cycle < #y then
            cycle = cycle + 1
        else
            cycle = 1
        end
    else
        if not texte then
            print("APPRENTISSAGE TERMINE")
            texte = true
        end
        -- sortie des couches cachee
        C = sortie(X, Wc, Bc, posx - 80, "relu")
        C2 = sortie(C, Wc2, Bc2, posx, "relu")
        -- sorties de la couche de sortie
        S = sortie(C2, Ws, Bs, posx + 80, "sigmoide")
        if hh <= #y then
            X = x[hh]
            Y = y[hh]
            --
            
            printMatrixln(X)
            print("=")
            printMatrixln(S)
            print("~")
            printMatrixln(Y)
            hh = hh + 1
            print("-------")
        end
    end
end
        
--# Fonctions

-- optimisation
function ajusterTeta(erreur)
    if erreur_prec == nil then
        erreur_prec = erreur
        return
    end
    
    if erreur < erreur_prec then
        teta = teta * 0.95  -- diminue doucement
    elseif erreur > erreur_prec or erreur == erreur_prec then
        teta = teta + 1  -- augmente légèrement
    end
    
    -- bornes pour éviter les extrêmes
    if teta > 5 then teta = 5 end
    if teta < 0.001 then teta = 0.001 end
    
    erreur_prec = erreur
end

function sigmoid_derivative_matrix(matrix1)
    result = {}
    for i = 1, #matrix1 do
        
        result[i] = matrix1[i] * (1 - matrix1[i])
    end
    return result
end

function sigmoid_matrix(matrix1)
    result = {}
    for i = 1, #matrix1 do
        result[i] = 1 / (1 + math.exp(-matrix1[i]))
    end
    return result
end
alpha = 0.001 -- petite pente

function leaky_relu_matrix(matrix1)
    local result = {}
    for i = 1, #matrix1 do
        if matrix1[i] > 0 then
            result[i] = matrix1[i]
        else
            result[i] = alpha * matrix1[i]
        end
    end
    return result
end

function leaky_relu_derivative_matrix(matrix1)
    local result = {}
    for i = 1, #matrix1 do
        if matrix1[i] > 0 then
            result[i] = 1
        else
            result[i] = alpha
        end
    end
    return result
end
function sortie(entre, poids, biais, posx, activation)
    sp = addMatrix(multiply_sum_Matrix2(poids, entre), biais)
    -- type d'activation
    if activation == "relu" then
        
        activation = leaky_relu_matrix(sp)
    elseif activation == "sigmoide" then
        activation = sigmoid_matrix(sp)
    end
    
    -- visuel de neurones
    local posx, posy = posx, HEIGHT/2 + (50 * #poids/2)
    coef = 500
    for i = 1, #poids do
        local posx2, posy2 = posx - 80, HEIGHT/2 + (50 * #entre/2)
        for j = 1, #poids[i] do
            -- dessin des poids
            stroke(activation[i] * coef, poids[i][j] * coef, biais[i] * coef)
            strokeWidth(poids[i][j] * coef/100)
            line(posx, posy, posx2, posy2)
            noStroke()
            posy2 = posy2 - 50
        end
        -- dessin des neurones
        stroke(255)
        strokeWidth(biais[i])
        fill(23, 255, activation[i] * coef)
        ellipse(posx, posy, 25)
        posy = posy - 50
    end
    --print(#poids)
    return activation
end

function maj_poids_biais_sortie(entre, poids, biais, sortie1, sortie2, activation)
    -- erreur
    local y = sortie2[cycle]
    erreur = subMatrix(y, sortie1)
    -- gradient couche de sortie
    
    if activation == "relu" then
        
        ds = leaky_relu_derivative_matrix(sortie1)
    elseif activation == "sigmoide" then
        ds = sigmoid_derivative_matrix(sortie1)
    end
    delta_s = multiplyMatrix(erreur, ds)
    -- mise a jour des poids
    -- sortie
    delta_s = multiplyScalar(delta_s, teta)
    --print(#entre[1])
    mat1 = {}
    for i = 1, #delta_s do
        mat1[i] = multiplyScalar(entre, delta_s[i])
    end
    
    nouveau_poids = addMatrix3(poids, mat1)
    nouveau_biais = addMatrix(biais , delta_s)
    
    return nouveau_poids, nouveau_biais, delta_s
end
function poids_biais(entre, nbr_neurone)
    -- tout les poids et biais des neurones d'une couche
    ini = 5
    matrix_poids1 = {} 
    matrix_poids2 = {}
    for i = 1, nbr_neurone do
        for j = 1, #entre do
            matrix_poids2[j] = -0.5 + (1.0) * math.random()   -- résultat entre -0.5 et 0.5
        end
        matrix_poids1[i] = matrix_poids2
    end
    matrix_biais = {}
    for i = 1, nbr_neurone do
        matrix_biais[i] = 1
    end
    return matrix_poids1, matrix_biais
end
function maj_poids_biais_cache(entre, poids1, poids2, biais, sortie, delta__, activation)
    -- gradient couche cache
    if activation == "relu" then
        
        dc = leaky_relu_derivative_matrix(sortie)
    elseif activation == "sigmoide" then
        dc = sigmoid_derivative_matrix(sortie)
    end
    
    -- calcule de delta_c
    local delta_c = {}
    for i = 1, #dc do
        mat = {}
        for j = 1, #poids1 do
            mat[j] = poids1[j][i] * delta__[j]
        end
        delta_c[i] = dc[i] * sumMatrix(mat)
    end
    --delta_c = delta(poids1, dc, poids1, delta__)
    -- entree
    delta_c = multiplyScalar(delta_c, teta)
    mat1 = {}
    for i = 1, #delta_c do
        mat1[i] = multiplyScalar(entre, delta_c[i])
    end
    nouveau_poids = addMatrix3(poids2, mat1)
    nouveau_biais = addMatrix(biais , delta_c)
    
    return nouveau_poids, nouveau_biais, delta_c
end

--# MatrixOp
function createMatrix()
    mat = {}
    return mat
end
-- matrice matrice
-- addition
function addMatrix(a, b)
    local result = createMatrix()
    for i = 1, #a do
        result[i] = a[i] + b[i]
    end
    return result
end
-- soustraction
function subMatrix(a, b)
    local result = createMatrix()
    for i = 1, #a do
        result[i] = a[i] - b[i]
    end
    return result
end
-- multiplication
function multiplyMatrix(a, b)
    local result = createMatrix()
    for i = 1, #a do
        result[i] = a[i] * b[i]
    end
    return result
end

-- division
function divideMatrix(a, b)
    local result = createMatrix()
    for i = 1, #a do
        result[i] = a[i] / b[i]
    end
    return result
end

-- matrice et nombre
function addScalar(mat, scalar)
    local result = createMatrix()
    for i = 1, #mat do
        result[i] = mat[i] + scalar
    end
    return result
end
-- soustraction
function subScalar(mat, scalar)
    local result = createMatrix()
    for i = 1, #mat do
        result[i] = mat[i] - scalar
    end
    return result
end
-- multiplication
function multiplyScalar(mat, scalar)
    local result = createMatrix()
    for i = 1, #mat do
        result[i] = mat[i] * scalar
    end
    return result
end
-- division
function divideScalar(mat, scalar)
    local result = createMatrix()
    for i = 1, #mat do
        result[i] = mat[i] / scalar
    end
    return result
end

-- somme de tout les elements d'une matrice
function sumMatrix(mat)
    nbr = 0
    for i = 1, #mat do
        nbr = nbr + mat[i]
    end
    return nbr
end
-- affichage
function printMatrix(mat)
    for i = 1, #mat do
        print(mat[i])
    end
end
function printMatrixln(mat)
    local a = ""
    for i = 1, #mat do
        a = a .. tostring(mat[i])
        if i ~= #mat then
            a = a .. ", "
        end
    end
    print(a)
end
function multiply_sum_Matrix2(matrix2, matrix1)
    result = {}
    for i = 1, #matrix2 do
        result[i] = sumMatrix(multiplyMatrix(matrix2[i], matrix1))
    end
    return result
end
function multiplyMatrix2(matrix2, matrix1)
    result = {}
    result2 = {}
    for i = 1, #matrix2 do
        for j = 1, #matrix1 do
            result2[j] = matrix2[i][j] * matrix1[j]
        end
        result[i] = result2
        result2 = {}
    end
    return result
end
function addMatrix2(matrix2, matrix1)
    result = {}
    result2 = {}
    for i = 1, #matrix2 do
        for j = 1, #matrix1 do
            result2[j] = matrix2[i][j] + matrix1[j]
        end
        result[i] = result2
        result2 = {}
    end
    return result
end
function addMatrix3(matrix1, matrix2)
    result = {}
    result2 = {}
    for i = 1, #matrix1 do
        for j = 1, #matrix1[i] do
            result2[j] = matrix1[i][j] + matrix2[i][j]
        end
        result[i] = result2
    end
    return result
end
function subScalarinv(scalar, mat)
    local result = createMatrix()
    for i = 1, #mat do
        result[i] =  math.abs(scalar - mat[i])
    end
    return result
end
function multiplyScalarabs(mat, scalar)
    local result = createMatrix()
    for i = 1, #mat do
        result[i] = math.abs(mat[i] * scalar)
    end
    return result
end
